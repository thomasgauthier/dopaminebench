FROM python:3.12

COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

WORKDIR /workspace

RUN apt-get update && apt-get install -y curl ca-certificates && rm -rf /var/lib/apt/lists/*
RUN curl -fsSL https://github.com/caddyserver/caddy/releases/download/v2.10.2/caddy_2.10.2_linux_amd64.tar.gz | tar -xz -C /usr/bin caddy
RUN curl -fsSL https://opencode.ai/install | bash

RUN mkdir -p /root/.config/opencode && cat > /root/.config/opencode/opencode.json << 'EOF'
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "local": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "ooba",
      "options": {
        "baseURL": "http://host.docker.internal:8080/v1"
      },
      "models": {
        "glm-4.7-flash": {
          "name": "glm-4.7-flash-reap-gguf"
        }
      }
    }
  },
  "disabled_providers": [
    "opencode"
  ]
}
EOF

COPY opencode-mcp/requirements.txt /app/requirements.txt
COPY opencode-mcp/server.py /app/server.py
COPY opencode-mcp/Caddyfile /etc/caddy/Caddyfile
COPY opentui /opentui

WORKDIR /app

RUN uv venv && uv pip install -r /app/requirements.txt

CMD caddy run --config /etc/caddy/Caddyfile & cd /opentui && /app/.venv/bin/fastmcp run /app/server.py:mcp --transport http --host localhost --port 8080
